{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":4509555,"sourceType":"datasetVersion","datasetId":2635620},{"sourceId":7896687,"sourceType":"datasetVersion","datasetId":4637105}],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-20T15:08:07.736385Z","iopub.execute_input":"2024-03-20T15:08:07.737265Z","iopub.status.idle":"2024-03-20T15:08:08.207059Z","shell.execute_reply.started":"2024-03-20T15:08:07.737228Z","shell.execute_reply":"2024-03-20T15:08:08.206028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport seaborn as sns\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix\n\nfrom tensorflow.keras.layers import Input, Dense, Flatten, Conv2D, MaxPooling2D, BatchNormalization, Dropout, LeakyReLU\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau","metadata":{"execution":{"iopub.status.busy":"2024-03-20T15:08:10.265703Z","iopub.execute_input":"2024-03-20T15:08:10.266223Z","iopub.status.idle":"2024-03-20T15:08:22.399473Z","shell.execute_reply.started":"2024-03-20T15:08:10.266192Z","shell.execute_reply":"2024-03-20T15:08:22.398438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cp -r '/kaggle/input/deepfake/deepfake_database' '/kaggle/working/deepfake_database'","metadata":{"execution":{"iopub.status.busy":"2024-03-20T15:08:29.971324Z","iopub.execute_input":"2024-03-20T15:08:29.971975Z","iopub.status.idle":"2024-03-20T15:09:44.212527Z","shell.execute_reply.started":"2024-03-20T15:08:29.971944Z","shell.execute_reply":"2024-03-20T15:09:44.211330Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 读取图片 [(image, label), (image, label), ...]\nlabels_name = ['df', 'real','ps']\nimg_size = 150\n\ndef get_data(data_dir):\n    images = []\n    labels = []\n\n    for label in labels_name: \n        path = os.path.join(data_dir, label)\n        class_num = labels_name.index(label)\n        for img in os.listdir(path):\n            try:\n                img_arr = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n                resized_arr = cv2.resize(img_arr, (img_size, img_size))\n                images.append(resized_arr)\n                labels.append(class_num)\n            except Exception as e:\n                print(e)\n\n    return np.array(images), np.array(labels)\n\nx_train, y_train = get_data('/kaggle/working/deepfake_database/train')\nx_test, y_test = get_data('/kaggle/working/deepfake_database/test')\nx_val, y_val = get_data('/kaggle/working/deepfake_database/validation')\n","metadata":{"execution":{"iopub.status.busy":"2024-03-20T15:09:44.214936Z","iopub.execute_input":"2024-03-20T15:09:44.215278Z","iopub.status.idle":"2024-03-20T15:10:32.243254Z","shell.execute_reply.started":"2024-03-20T15:09:44.215239Z","shell.execute_reply":"2024-03-20T15:10:32.242361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train = np.array(x_train) / 255\nx_val = np.array(x_val) / 255\nx_test = np.array(x_test) / 255\n\n# resize data for deep learning \nx_train = x_train.reshape(-1, img_size, img_size, 1)\ny_train = np.array(y_train)\n\nx_val = x_val.reshape(-1, img_size, img_size, 1)\ny_val = np.array(y_val)\n\nx_test = x_test.reshape(-1, img_size, img_size, 1)\ny_test = np.array(y_test)\n\nx_test[0].shape\ny_train = y_train.reshape(-1,1)\ny_test = y_test.reshape(-1,1)\ny_val = y_val.reshape(-1,1)","metadata":{"execution":{"iopub.status.busy":"2024-03-20T14:54:00.361783Z","iopub.execute_input":"2024-03-20T14:54:00.362610Z","iopub.status.idle":"2024-03-20T14:54:01.663447Z","shell.execute_reply.started":"2024-03-20T14:54:00.362575Z","shell.execute_reply":"2024-03-20T14:54:01.662481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"datagen = ImageDataGenerator()\ndatagen.fit(x_train)\n\nmodel = tf.keras.Sequential()\nmodel.add(Conv2D(8 , (3,3) ,padding = 'same' , activation = 'relu' , input_shape = (150,150,1) ))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D((2,2) ,padding = 'same') )\n\nmodel.add(Conv2D(8 , (5,5) ,padding = 'same' , activation = 'relu') )\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D((2,2) ,padding = 'same'))\n\nmodel.add(Conv2D(16 , (5,5) ,padding = 'same' , activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D((2,2) ,padding = 'same'))\n\nmodel.add(Conv2D(16 , (5,5) ,padding = 'same' , activation = 'relu' ))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D((4,24) ,padding = 'same'))\n\nmodel.add(Flatten())\nmodel.add(Dropout(0.5))\nmodel.add(Dense(16))\nmodel.add(LeakyReLU(alpha=0.1))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1, activation = 'sigmoid'))\nmodel.compile(optimizer = 'Adam' , loss = 'binary_crossentropy' , metrics = ['accuracy'])\n\nbatch_size = 4\nepochs = 10\n\nhistory = model.fit(datagen.flow(x_train,y_train,\n         batch_size = batch_size),epochs=epochs,\n         validation_data = datagen.flow(x_val, y_val),\n         verbose=1)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2024-03-20T14:54:10.509460Z","iopub.execute_input":"2024-03-20T14:54:10.510322Z","iopub.status.idle":"2024-03-20T14:56:22.258308Z","shell.execute_reply.started":"2024-03-20T14:54:10.510288Z","shell.execute_reply":"2024-03-20T14:56:22.257453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nmodel_name = \"CNN\"\nresult = model.evaluate(x_test,y_test)\nloss = result[0]\naccuracy = result[1]*100\n\ndf = pd.DataFrame({'Model': [model_name], 'Loss': [loss], 'Accuracy (%)': [accuracy]})\n\nfig, ax = plt.subplots()\nax.axis('tight')\nax.axis('off')\nax.table(cellText=df.values, colLabels=df.columns, loc='center')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-03-20T14:56:45.886420Z","iopub.execute_input":"2024-03-20T14:56:45.887132Z","iopub.status.idle":"2024-03-20T14:56:47.267984Z","shell.execute_reply.started":"2024-03-20T14:56:45.887099Z","shell.execute_reply":"2024-03-20T14:56:47.266448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Torch","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, transforms\n\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])\n\ntrain_dataset = datasets.ImageFolder('/kaggle/working/deepfake_database/train', transform=transform)\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n\nval_dataset = datasets.ImageFolder('/kaggle/working/deepfake_database/validation', transform=transform)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n\ntest_dataset = datasets.ImageFolder('/kaggle/working/deepfake_database/test', transform=transform)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-03-20T15:12:55.130090Z","iopub.execute_input":"2024-03-20T15:12:55.130829Z","iopub.status.idle":"2024-03-20T15:12:56.630059Z","shell.execute_reply.started":"2024-03-20T15:12:55.130796Z","shell.execute_reply":"2024-03-20T15:12:56.629181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import DeiTForImageClassification\n\nmodel = DeiTForImageClassification.from_pretrained(\"facebook/deit-base-distilled-patch16-224\", num_labels=2)","metadata":{"execution":{"iopub.status.busy":"2024-03-20T15:13:00.161742Z","iopub.execute_input":"2024-03-20T15:13:00.162117Z","iopub.status.idle":"2024-03-20T15:13:22.950643Z","shell.execute_reply.started":"2024-03-20T15:13:00.162075Z","shell.execute_reply":"2024-03-20T15:13:22.949735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.optim import AdamW\nfrom tqdm import tqdm\nimport torch\nfrom torch.nn import DataParallel\nfrom sklearn.metrics import accuracy_score\n\nif torch.cuda.is_available():\n    device = torch.device(\"cuda\")\n    print(\"Using\", torch.cuda.device_count(), \"GPUs\")\n    model = DataParallel(model)\n    model.to(device)\nelse:\n    device = torch.device(\"cpu\")\n    print(\"Using CPU\")\n\noptimizer = AdamW(model.parameters(), lr=0.0001)\ncriterion = torch.nn.CrossEntropyLoss()\n\ntotal_accuracy = 0\ntotal_loss = 0\nnum_batches = 0\nmodel.train()\n\nfor epoch in range(1):\n    epoch_loss = 0\n    for batch in tqdm(train_loader):\n        inputs, labels = batch\n\n        inputs, labels = inputs.to(device), labels.to(device)\n\n        optimizer.zero_grad()\n        outputs = model(inputs).logits\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        epoch_loss += loss.item()\n        num_batches += 1\n\n    avg_epoch_loss = epoch_loss / num_batches\n    total_loss += avg_epoch_loss\n\n    model.eval()\n    val_labels = []\n    val_preds = []\n    with torch.no_grad():\n        for batch in val_loader:\n            inputs, labels = batch\n            inputs, labels = inputs.to(device), labels.to(device)\n\n            outputs = model(inputs).logits\n            _, preds = torch.max(outputs, 1)\n            val_labels.extend(labels.cpu().numpy())\n            val_preds.extend(preds.cpu().numpy())\n\n    val_accuracy = accuracy_score(val_labels, val_preds)\n    total_accuracy += val_accuracy\n    print(f'Epoch {epoch+1}/{10}, Loss: {avg_epoch_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')","metadata":{"execution":{"iopub.status.busy":"2024-03-20T15:13:26.283320Z","iopub.execute_input":"2024-03-20T15:13:26.283686Z","iopub.status.idle":"2024-03-20T15:13:28.534455Z","shell.execute_reply.started":"2024-03-20T15:13:26.283659Z","shell.execute_reply":"2024-03-20T15:13:28.533067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"D2l","metadata":{}},{"cell_type":"code","source":"!pip install d2l==1.0.3","metadata":{"execution":{"iopub.status.busy":"2024-03-20T15:18:47.234201Z","iopub.execute_input":"2024-03-20T15:18:47.235231Z","iopub.status.idle":"2024-03-20T15:19:42.783617Z","shell.execute_reply.started":"2024-03-20T15:18:47.235189Z","shell.execute_reply":"2024-03-20T15:19:42.782577Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport shutil\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision.transforms as transforms\nfrom torchvision.models import resnet18\nfrom torch.utils.data import DataLoader\nfrom torchvision.datasets import ImageFolder\nimport pandas as pd\nimport torchvision\nfrom d2l import torch as d2l","metadata":{"execution":{"iopub.status.busy":"2024-03-20T15:19:50.230580Z","iopub.execute_input":"2024-03-20T15:19:50.231459Z","iopub.status.idle":"2024-03-20T15:19:50.237394Z","shell.execute_reply.started":"2024-03-20T15:19:50.231423Z","shell.execute_reply":"2024-03-20T15:19:50.236322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport tensorflow.keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout , BatchNormalization\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report,confusion_matrix\nfrom keras.callbacks import ReduceLROnPlateau\nimport cv2\nimport os\nimport numpy as np\nimport pandas as pd\nfrom keras.models import Sequential\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2024-03-20T15:24:52.444815Z","iopub.execute_input":"2024-03-20T15:24:52.445485Z","iopub.status.idle":"2024-03-20T15:24:52.451921Z","shell.execute_reply.started":"2024-03-20T15:24:52.445454Z","shell.execute_reply":"2024-03-20T15:24:52.450940Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.layers import Input, Dense, Flatten, Conv2D, MaxPooling2D, BatchNormalization, Dropout, Reshape, Concatenate, LeakyReLU\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import Model\nimport sklearn.preprocessing \nfrom sklearn.preprocessing import LabelEncoder","metadata":{"execution":{"iopub.status.busy":"2024-03-20T15:25:04.122759Z","iopub.execute_input":"2024-03-20T15:25:04.123127Z","iopub.status.idle":"2024-03-20T15:25:04.128963Z","shell.execute_reply.started":"2024-03-20T15:25:04.123100Z","shell.execute_reply":"2024-03-20T15:25:04.128063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_dir='/kaggle/working/deepfake_database'","metadata":{"execution":{"iopub.status.busy":"2024-03-20T15:20:20.087404Z","iopub.execute_input":"2024-03-20T15:20:20.088089Z","iopub.status.idle":"2024-03-20T15:20:20.092293Z","shell.execute_reply.started":"2024-03-20T15:20:20.088057Z","shell.execute_reply":"2024-03-20T15:20:20.091259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# generate labels\nlabels = ['df', 'real','ps']\nimg_size = 150\ndef get_data(data_dir):\n    data = [] \n    for label in labels: \n        path = os.path.join(data_dir, label)\n        class_num = labels.index(label)\n        #print(class_num)\n        for img in os.listdir(path):\n            try:\n                #img_arr = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n                #resized_arr = cv2.resize(img_arr, (img_size, img_size)) # Reshaping images to preferred size\n                #print(img)\n                resized_arr=img.split(\".\")[0]\n                data.append([resized_arr, class_num])\n            except Exception as e:\n                print(e)\n    return data","metadata":{"execution":{"iopub.status.busy":"2024-03-20T15:21:32.988124Z","iopub.execute_input":"2024-03-20T15:21:32.988555Z","iopub.status.idle":"2024-03-20T15:21:32.996767Z","shell.execute_reply.started":"2024-03-20T15:21:32.988524Z","shell.execute_reply":"2024-03-20T15:21:32.995585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_test = get_data('/kaggle/working/deepfake_database/test')\ndata_train = get_data('/kaggle/working/deepfake_database/train')\nfor i in data_test:\n    data_train.append(i)\n    \ndata_label=data_train\n\nx=[]\ny=[]\n\nfor feature, label in data_label:\n    x.append(feature)\n    y.append(label)\n    \nlabel = pd.DataFrame({'name':x,'label':y})","metadata":{"execution":{"iopub.status.busy":"2024-03-20T15:22:20.222436Z","iopub.execute_input":"2024-03-20T15:22:20.223032Z","iopub.status.idle":"2024-03-20T15:22:20.259245Z","shell.execute_reply.started":"2024-03-20T15:22:20.223004Z","shell.execute_reply":"2024-03-20T15:22:20.258532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert the DataFrame to a CSV string with a specified delimiter (comma by default)\ncsv_string = label.to_string(index=False)\n#print(csv_string)\n# Split the CSV string into a list of lines\ncsv_lines = csv_string.split('\\n')\n#print(csv_lines)\n# Save the CSV lines to a file using Python's built-in file I/O functions\nwith open('/kaggle/working/deepfake_database/train/labels.csv', 'w') as csvfile:\n    for line in csv_lines:\n        # Split the line by whitespace\n        row = line.split()\n        csvfile.write(row[0]+','+row[1]+'\\n')","metadata":{"execution":{"iopub.status.busy":"2024-03-20T15:23:02.433945Z","iopub.execute_input":"2024-03-20T15:23:02.434348Z","iopub.status.idle":"2024-03-20T15:23:02.593094Z","shell.execute_reply.started":"2024-03-20T15:23:02.434319Z","shell.execute_reply":"2024-03-20T15:23:02.592176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def copyfile(filename, target_dir):\n    \"\"\"将文件复制到目标目录\"\"\"\n    os.makedirs(target_dir, exist_ok=True)\n    shutil.copy(filename, target_dir)\n    \ndef read_csv_labels(fname):\n    \"\"\"读取fname来给标签字典返回一个文件名\"\"\"\n    with open(fname, 'r') as f:\n        # 跳过文件头行(列名)\n        lines = f.readlines()[1:]\n    tokens = [l.rstrip().split(',') for l in lines]\n    return dict(((name, label) for name, label in tokens))\nlabels = read_csv_labels(os.path.join(\"/kaggle/working/deepfake_database/train\", 'labels.csv'))\nprint('# 训练样本 :', len(labels))\nprint('# 类别 :', len(set(labels.values())))","metadata":{"execution":{"iopub.status.busy":"2024-03-20T15:26:45.439202Z","iopub.execute_input":"2024-03-20T15:26:45.440381Z","iopub.status.idle":"2024-03-20T15:26:45.460764Z","shell.execute_reply.started":"2024-03-20T15:26:45.440338Z","shell.execute_reply":"2024-03-20T15:26:45.459691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def reorg_train_valid(data_dir, labels, valid_ratio):\n    \"\"\"将验证集从原始的训练集中拆分出来\"\"\"\n    # 训练数据集中样本最少的类别中的样本数\n    n = collections.Counter(labels.values()).most_common()[-1][1]\n    # 验证集中每个类别的样本数\n    n_valid_per_label = max(1, math.floor(n * valid_ratio))\n    label_count = {}\n    # 遍历训练集中的所有图片\n    for train_file in os.listdir(os.path.join(data_dir, 'train')):\n        # 获取图片对应的label\n        label = labels[train_file.split('.')[0]]\n        # 获取图片地址\n        fname = os.path.join(data_dir, 'train', train_file)\n        # 将图片复制到label对应的文件夹下\n        copyfile(fname, os.path.join(data_dir, 'train_valid_test',\n                                     'train_valid', label))\n        # 如果验证集还没存满，则把图片存到对应label的验证集下\n        if label not in label_count or label_count[label] < n_valid_per_label:\n            copyfile(fname, os.path.join(data_dir, 'train_valid_test',\n                                         'valid', label))\n            label_count[label] = label_count.get(label, 0) + 1\n        # 如果验证集存满了，则把图片存到对应label的训练集下    \n        else:\n            copyfile(fname, os.path.join(data_dir, 'train_valid_test',\n                                         'train', label))\n    return n_valid_per_label","metadata":{"execution":{"iopub.status.busy":"2024-03-20T15:26:48.472893Z","iopub.execute_input":"2024-03-20T15:26:48.473620Z","iopub.status.idle":"2024-03-20T15:26:48.481948Z","shell.execute_reply.started":"2024-03-20T15:26:48.473590Z","shell.execute_reply":"2024-03-20T15:26:48.480950Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 调整训练集与预测集，将图片放到train文件夹下\nfor train_file in os.listdir(os.path.join(\"/kaggle/working/deepfake_database/train\", 'df')):\n    fname = os.path.join(\"/kaggle/working/deepfake_database/train\", 'df', train_file)\n    copyfile(fname,\"/kaggle/working/deepfake_database/train/train\")","metadata":{"execution":{"iopub.status.busy":"2024-03-20T15:26:50.680934Z","iopub.execute_input":"2024-03-20T15:26:50.681334Z","iopub.status.idle":"2024-03-20T15:26:51.311097Z","shell.execute_reply.started":"2024-03-20T15:26:50.681305Z","shell.execute_reply":"2024-03-20T15:26:51.310048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for train_file in os.listdir(os.path.join(\"/kaggle/working/deepfake_database/train\", 'real')):\n    fname = os.path.join(\"/kaggle/working/deepfake_database/train\", 'real', train_file)\n    copyfile(fname,\"/kaggle/working/deepfake_database/train/train\")","metadata":{"execution":{"iopub.status.busy":"2024-03-20T15:27:16.874553Z","iopub.execute_input":"2024-03-20T15:27:16.874944Z","iopub.status.idle":"2024-03-20T15:27:17.793857Z","shell.execute_reply.started":"2024-03-20T15:27:16.874915Z","shell.execute_reply":"2024-03-20T15:27:17.793070Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for train_file in os.listdir(os.path.join(\"/kaggle/working/deepfake_database/train\", 'ps')):\n    fname = os.path.join(\"/kaggle/working/deepfake_database/train\", 'ps', train_file)\n    copyfile(fname,\"/kaggle/working/deepfake_database/train/train\")","metadata":{"execution":{"iopub.status.busy":"2024-03-20T15:28:04.395423Z","iopub.execute_input":"2024-03-20T15:28:04.395790Z","iopub.status.idle":"2024-03-20T15:28:05.272986Z","shell.execute_reply.started":"2024-03-20T15:28:04.395765Z","shell.execute_reply":"2024-03-20T15:28:05.272169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for test_file in os.listdir(os.path.join(\"/kaggle/working/deepfake_database/test\", 'df')):\n    fname = os.path.join(\"/kaggle/working/deepfake_database/test\", 'df', test_file)\n    copyfile(fname,\"/kaggle/working/deepfake_database/train/test\")","metadata":{"execution":{"iopub.status.busy":"2024-03-20T15:28:16.574250Z","iopub.execute_input":"2024-03-20T15:28:16.574649Z","iopub.status.idle":"2024-03-20T15:28:16.604759Z","shell.execute_reply.started":"2024-03-20T15:28:16.574618Z","shell.execute_reply":"2024-03-20T15:28:16.603979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for test_file in os.listdir(os.path.join(\"/kaggle/working/deepfake_database/test\", 'real')):\n    fname = os.path.join(\"/kaggle/working/deepfake_database/test\", 'real', test_file)\n    copyfile(fname,\"/kaggle/working/deepfake_database/train/test\")","metadata":{"execution":{"iopub.status.busy":"2024-03-20T15:28:26.061547Z","iopub.execute_input":"2024-03-20T15:28:26.061906Z","iopub.status.idle":"2024-03-20T15:28:26.090051Z","shell.execute_reply.started":"2024-03-20T15:28:26.061880Z","shell.execute_reply":"2024-03-20T15:28:26.089370Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for test_file in os.listdir(os.path.join(\"/kaggle/working/deepfake_database/test\", 'ps')):\n    fname = os.path.join(\"/kaggle/working/deepfake_database/test\", 'ps', test_file)\n    copyfile(fname,\"/kaggle/working/deepfake_database/train/test\")","metadata":{"execution":{"iopub.status.busy":"2024-03-20T15:28:59.128629Z","iopub.execute_input":"2024-03-20T15:28:59.129004Z","iopub.status.idle":"2024-03-20T15:28:59.193623Z","shell.execute_reply.started":"2024-03-20T15:28:59.128976Z","shell.execute_reply":"2024-03-20T15:28:59.192781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 切分训练集与预测集\n\ndef reorg_dog_data(data_dir, valid_ratio):\n    labels = d2l.read_csv_labels(os.path.join(\"/kaggle/working/deepfake_database/train\", 'labels.csv'))\n    d2l.reorg_train_valid(data_dir, labels, valid_ratio)\n    d2l.reorg_test(data_dir)\n    \nbatch_size = 128\nvalid_ratio = 0.1\nreorg_dog_data(\"/kaggle/working/deepfake_database/train\", valid_ratio)","metadata":{"execution":{"iopub.status.busy":"2024-03-20T15:29:09.899389Z","iopub.execute_input":"2024-03-20T15:29:09.900102Z","iopub.status.idle":"2024-03-20T15:29:15.267692Z","shell.execute_reply.started":"2024-03-20T15:29:09.900070Z","shell.execute_reply":"2024-03-20T15:29:15.266716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 构造feather\ntransform_train = torchvision.transforms.Compose([\n    # Randomly crop the image to obtain an image with an area of 0.08 to 1 of\n    # the original area and height-to-width ratio between 3/4 and 4/3. Then,\n    # scale the image to create a new 224 x 224 image\n    torchvision.transforms.RandomResizedCrop(224, scale=(0.08, 1.0),\n                                             ratio=(3.0/4.0, 4.0/3.0)),\n    torchvision.transforms.RandomHorizontalFlip(),\n    # Randomly change the brightness, contrast, and saturation\n    torchvision.transforms.ColorJitter(brightness=0.4,\n                                       contrast=0.4,\n                                       saturation=0.4),\n    # Add random noise\n    torchvision.transforms.ToTensor(),\n    # Standardize each channel of the image\n    torchvision.transforms.Normalize([0.485, 0.456, 0.406],\n                                     [0.229, 0.224, 0.225])])\n\ntransform_test = torchvision.transforms.Compose([\n    torchvision.transforms.Resize(256),\n    # Crop a 224 x 224 square area from the center of the image\n    torchvision.transforms.CenterCrop(224),\n    torchvision.transforms.ToTensor(),\n    torchvision.transforms.Normalize([0.485, 0.456, 0.406],\n                                     [0.229, 0.224, 0.225])])","metadata":{"execution":{"iopub.status.busy":"2024-03-20T15:29:25.011697Z","iopub.execute_input":"2024-03-20T15:29:25.012365Z","iopub.status.idle":"2024-03-20T15:29:25.020209Z","shell.execute_reply.started":"2024-03-20T15:29:25.012333Z","shell.execute_reply":"2024-03-20T15:29:25.019228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_data_dir=\"/kaggle/working/deepfake_database/train\"","metadata":{"execution":{"iopub.status.busy":"2024-03-20T15:29:34.305964Z","iopub.execute_input":"2024-03-20T15:29:34.306687Z","iopub.status.idle":"2024-03-20T15:29:34.310682Z","shell.execute_reply.started":"2024-03-20T15:29:34.306659Z","shell.execute_reply":"2024-03-20T15:29:34.309708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ds, train_valid_ds = [torchvision.datasets.ImageFolder(\n    os.path.join(new_data_dir, 'train_valid_test', folder),\n    transform=transform_train) for folder in ['train', 'train_valid']]\n\nvalid_ds, test_ds = [torchvision.datasets.ImageFolder(\n    os.path.join(new_data_dir, 'train_valid_test', folder),\n    transform=transform_test) for folder in ['valid', 'test']]\n\ntrain_iter, train_valid_iter = [torch.utils.data.DataLoader(\n    dataset, batch_size, shuffle=True, drop_last=True)\n    for dataset in (train_ds, train_valid_ds)]\n\nvalid_iter = torch.utils.data.DataLoader(valid_ds, batch_size, shuffle=False,\n                                         drop_last=True)\n\ntest_iter = torch.utils.data.DataLoader(test_ds, batch_size, shuffle=False,\n                                        drop_last=False)","metadata":{"execution":{"iopub.status.busy":"2024-03-20T15:29:50.811814Z","iopub.execute_input":"2024-03-20T15:29:50.812503Z","iopub.status.idle":"2024-03-20T15:29:50.936823Z","shell.execute_reply.started":"2024-03-20T15:29:50.812472Z","shell.execute_reply":"2024-03-20T15:29:50.936072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 构造模型\ndef get_net(devices):\n    finetune_net = nn.Sequential()\n    finetune_net.features = torchvision.models.vit_l_16(pretrained=True)\n    # Define a new output network (there are 120 output categories)\n    finetune_net.output_new = nn.Sequential(nn.Linear(1000, 256),\n                                            nn.ReLU(),\n                                            nn.Linear(256, 120))\n    # Move the model to devices\n    finetune_net = finetune_net.to(devices[0])\n    # Freeze parameters of feature layers\n    for param in finetune_net.features.parameters():\n        param.requires_grad = False\n    return finetune_net","metadata":{"execution":{"iopub.status.busy":"2024-03-20T15:30:00.766319Z","iopub.execute_input":"2024-03-20T15:30:00.766683Z","iopub.status.idle":"2024-03-20T15:30:00.773182Z","shell.execute_reply.started":"2024-03-20T15:30:00.766655Z","shell.execute_reply":"2024-03-20T15:30:00.772229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss = nn.CrossEntropyLoss(reduction='none')\n\ndef evaluate_loss(data_iter, net, devices):\n    l_sum, n = 0.0, 0\n    for features, labels in data_iter:\n        features, labels = features.to(devices[0]), labels.to(devices[0])\n        outputs = net(features)\n        l = loss(outputs, labels)\n        l_sum += l.sum()\n        n += labels.numel()\n    return l_sum / n","metadata":{"execution":{"iopub.status.busy":"2024-03-20T15:30:10.494170Z","iopub.execute_input":"2024-03-20T15:30:10.494538Z","iopub.status.idle":"2024-03-20T15:30:10.500700Z","shell.execute_reply.started":"2024-03-20T15:30:10.494509Z","shell.execute_reply":"2024-03-20T15:30:10.499698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(net, train_iter, valid_iter, num_epochs, lr, wd, devices, lr_period,\n          lr_decay):\n    # Only train the small custom output network\n    net = nn.DataParallel(net, device_ids=devices).to(devices[0])\n    trainer = torch.optim.SGD((param for param in net.parameters()\n                               if param.requires_grad), lr=lr,\n                              momentum=0.9, weight_decay=wd)\n    scheduler = torch.optim.lr_scheduler.StepLR(trainer, lr_period, lr_decay)\n    num_batches, timer = len(train_iter), d2l.Timer()\n    legend = ['train loss']\n    if valid_iter is not None:\n        legend.append('valid loss')\n    animator = d2l.Animator(xlabel='epoch', xlim=[1, num_epochs],\n                            legend=legend)\n    for epoch in range(num_epochs):\n        metric = d2l.Accumulator(2)\n        for i, (features, labels) in enumerate(train_iter):\n            timer.start()\n            features, labels = features.to(devices[0]), labels.to(devices[0])\n            trainer.zero_grad()\n            output = net(features)\n            l = loss(output, labels).sum()\n            l.backward()\n            trainer.step()\n            metric.add(l, labels.shape[0])\n            timer.stop()\n            if (i + 1) % (num_batches // 5) == 0 or i == num_batches - 1:\n                animator.add(epoch + (i + 1) / num_batches,\n                             (metric[0] / metric[1], None))\n        measures = f'train loss {metric[0] / metric[1]:.3f}'\n        if valid_iter is not None:\n            valid_loss = evaluate_loss(valid_iter, net, devices)\n            animator.add(epoch + 1, (None, valid_loss.detach().cpu()))\n        scheduler.step()\n    if valid_iter is not None:\n        measures += f', valid loss {valid_loss:.3f}'\n    print(measures + f'\\n{metric[1] * num_epochs / timer.sum():.1f}'\n          f' examples/sec on {str(devices)}')","metadata":{"execution":{"iopub.status.busy":"2024-03-20T15:30:31.180467Z","iopub.execute_input":"2024-03-20T15:30:31.181162Z","iopub.status.idle":"2024-03-20T15:30:31.192999Z","shell.execute_reply.started":"2024-03-20T15:30:31.181133Z","shell.execute_reply":"2024-03-20T15:30:31.192085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 训练\ndevices, num_epochs, lr, wd = d2l.try_all_gpus(), 5, 1e-4, 1e-4\nlr_period, lr_decay, net = 2, 0.9, get_net(devices)\ntrain(net, train_iter, valid_iter, num_epochs, lr, wd, devices, lr_period,\n      lr_decay)","metadata":{"execution":{"iopub.status.busy":"2024-03-20T15:30:43.667894Z","iopub.execute_input":"2024-03-20T15:30:43.668277Z","iopub.status.idle":"2024-03-20T15:31:53.156698Z","shell.execute_reply.started":"2024-03-20T15:30:43.668237Z","shell.execute_reply":"2024-03-20T15:31:53.155224Z"},"trusted":true},"execution_count":null,"outputs":[]}]}